{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbbe4011",
   "metadata": {},
   "source": [
    "## IMPORT DATA + LIBRARY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d533c46c",
   "metadata": {},
   "source": [
    "<p> Cette partie est dédiée à l'import de spark, nécéssaire à la suite du projet. Le projet à pour objectif de coder un Kmeadian, celui-ci s'utilisera sur une base de donnée binaire. La base de donnée est composée d'individus,  qui après reshape, forment des chiffes.<p>\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762b233f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%classpath add mvn org.apache.spark spark-sql_2.11 2.4.4\n",
    "org.apache.log4j.Logger.getRootLogger().setLevel(org.apache.log4j.Level.ERROR);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741536a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%classpath add mvn org.apache.spark spark-mllib_2.11 2.4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1869deec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "val spark = SparkSession.builder()\n",
    "                        .appName(\"Simple Application\")\n",
    "                        .master(\"local[4]\")\n",
    "                        .config(\"spark.ui.enabled\", \"false\")\n",
    "                        .getOrCreate()\n",
    "val sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3aca3ce",
   "metadata": {},
   "source": [
    "## KMEDIAN FINAL VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdacfd9",
   "metadata": {},
   "source": [
    "<p> Le code est écrit à l'aide de classes, les classes sont héréditaires. La distance utilisée est la distance de Hamming, celle-ci est codée en XOR. L'algorithme à pour paramètre une liste de Point (classe), le nombre de clusters et le nombre d'itérations. Nous avons essayé de mapReduce l'algorithme afin d'obtenir de meilleures performances.<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b53f402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scala.util.Random\n",
    "\n",
    "case class Point(x: List[Int]){\n",
    "    def hd( b: List[Int]) = { \n",
    "    var c = Array[Int]()\n",
    "    var i = 0\n",
    "    while(i < this.x.length) {  \n",
    "        c = c :+ (this.x(i)^b(i))\n",
    "        i+=1 }\n",
    "    c.sum\n",
    "    }\n",
    "}\n",
    "\n",
    "case class Cluster(centroid: Point, points: List[Point] = Nil)\n",
    "\n",
    "case class ClusterBatch(clusters: List[Cluster])\n",
    "\n",
    "\n",
    "def Kmedian(allPoints: List[Point], n: Int, k: Int): List[ClusterBatch]= {\n",
    "    var innitCluster = initialClusters(allPoints, n)\n",
    "    var initialBatch = ClusterBatch(innitCluster)\n",
    "    var assignedClusters = List[Cluster]()\n",
    "    var reCentered : ClusterBatch = null\n",
    "    var i = 0\n",
    "    while(i < k){\n",
    "        assignedClusters = assignement(allPoints, initialBatch.clusters)\n",
    "        reCentered = ClusterBatch(assignedClusters)\n",
    "        i = i+1    \n",
    "    }\n",
    "    List(reCentered)\n",
    "}\n",
    "\n",
    "def assignement(allPoints: List[Point], clusters: List[Cluster]): List[Cluster] = {\n",
    "    val ptsByCluster = allPoints.groupBy(p => clusters.minBy(_.centroid.hd(p.x)))\n",
    "    clusters.map(c =>\n",
    "        c.copy(points = ptsByCluster.getOrElse(c, Nil))\n",
    "    )\n",
    "}\n",
    "\n",
    "def initialClusters(allPts: List[Point], n: Int): List[Cluster] = \n",
    "    Random.shuffle(allPts).take(n).map(pt => Cluster(pt))\n",
    "\n",
    "def reCenter(clusters: List[Cluster]): List[Cluster] = clusters.map { c =>\n",
    "    var sumVect = List[Int]()\n",
    "    var newCentroid = List[Int]()\n",
    "    var barycenter = List[Int]()\n",
    "    sumVect = c.points.map(_.x).transpose.map(_.sum)\n",
    "    barycenter = sumVect.map( j => if(j >= (c.points.size+1)/2 ){1}else{0})\n",
    "    c.copy(centroid = Point(barycenter))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec16c72",
   "metadata": {},
   "source": [
    "## DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b72ea84",
   "metadata": {},
   "source": [
    "<p> C'est ici que la base de donnée est importée, il y a quelques modifications à effectuer pour qu'elle soit intégrable à l'algorithme. <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8151e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "val Digits = spark.read\n",
    "  .option(\"header\", \"false\")\n",
    "  .option(\"inferSchema\", \"true\")\n",
    "  .csv(\"data/digits.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f614f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "val zero = Digits.take(Digits.count.toInt).toList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0480f86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val data = zero.map{ c=>\n",
    "    var correction = List[Int]()\n",
    "    for(i <- 0 until c.size){\n",
    "        correction = correction :+ c(i).asInstanceOf[Int]   \n",
    "    }\n",
    "    correction\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ccb702",
   "metadata": {},
   "outputs": [],
   "source": [
    "val dataFinal = data.map{n=>\n",
    "    Point(n)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e593359a",
   "metadata": {},
   "source": [
    "# KMEDIAN RESULT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c51155",
   "metadata": {},
   "source": [
    "<p> Voici les résultats, le Kmedian est plutot long à lançer, mais il fonctionne <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44638841",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "val result = Kmedian(dataFinal, 10, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5760ba8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val meanDigits = result(0).clusters.map(_.centroid.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a6e9b7",
   "metadata": {},
   "source": [
    "## DATA VIZUALISATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d69de8",
   "metadata": {},
   "source": [
    "<p> Nous avons décidé de reshape les centroids de chaque clusters afin de déterminer si celui-ci fonctionne bien. L'objectif est d'avoir tous les chiffes affichés (de 0 à 9). <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af26083",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%python\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from beakerx.object import beakerx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f93794f",
   "metadata": {},
   "outputs": [],
   "source": [
    "beakerx.meanDigitPython = meanDigits.map(_.toSeq.toArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105925c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%python\n",
    "\n",
    "data = pd.DataFrame(beakerx.meanDigitPython)\n",
    "for i in range(len(data)):\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    uniform_data = np.reshape(list(data.iloc[i,:]), (16, 15))\n",
    "    sns.heatmap(uniform_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd1b16f",
   "metadata": {},
   "source": [
    "Projet réalisé par : AIT MOHEMO Hamza, MAIZA Fares, GROSJEAN Adrien, RACHATI Imad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "",
   "name": "Scala",
   "nbconverter_exporter": "",
   "version": "2.11.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "89px",
    "width": "474px"
   },
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
